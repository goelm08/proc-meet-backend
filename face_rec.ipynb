{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "\n",
    "known_path = \"known_faces\"  # Set the path to your known faces folder\n",
    "unknown_path = \"unknown_faces\"  # Set the path to your unknown faces folder\n",
    "\n",
    "encodings = []\n",
    "\n",
    "def register_face(name, known_path):\n",
    "    dirOld = os.getcwd()\n",
    "    global encodings\n",
    "\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "    ret, frame = video_capture.read()\n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "    rgb_small_frame = small_frame[:, :, ::-1]\n",
    "    face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "    face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "    dir = os.path.join(known_path, name)\n",
    "    print(dir)\n",
    "    print(os.getcwd())\n",
    "    if not os.path.isdir(dir):\n",
    "        os.mkdir(dir)\n",
    "    os.chdir(known_path)\n",
    "    os.chdir(name)\n",
    "    rand_no = np.random.random_sample()\n",
    "    cv2.imwrite(f\"{rand_no}.jpg\", frame)\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    for i in face_encodings:\n",
    "        encodings.append((name, i))\n",
    "    os.chdir(dirOld)\n",
    "\n",
    "def recognize_face(known_path, unknown_path):\n",
    "    dirOld = os.getcwd()\n",
    "    global encodings\n",
    "\n",
    "    known_face_encodings = [i[1] for i in encodings]\n",
    "    known_face_names = [i[0] for i in encodings]\n",
    "\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "    ret, frame = video_capture.read()\n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "    rgb_small_frame = small_frame[:, :, ::-1]\n",
    "    face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "    face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "    face_names = []\n",
    "\n",
    "    if not face_encodings:\n",
    "        msg = \"You are unknown first register your self\"\n",
    "    else:\n",
    "        for face_encoding in face_encodings:\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if matches[best_match_index]:\n",
    "                name = known_face_names[best_match_index]\n",
    "            if name == \"Unknown\":\n",
    "                msg = \"You are unknown first register your self\"\n",
    "            else:\n",
    "                msg = name\n",
    "            face_names.append(name)\n",
    "\n",
    "        for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "            top *= 4\n",
    "            right *= 4\n",
    "            bottom *= 4\n",
    "            left *= 4\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "            cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "        os.chdir(unknown_path)\n",
    "        rand_no = np.random.random_sample()\n",
    "        cv2.imwrite(f\"{rand_no}.jpg\", frame)\n",
    "    os.chdir(dirOld)\n",
    "    return msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: List[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: List[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: List[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n\nInvoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000002010F6CF430>, array([[[137, 142, 133],\n        [133, 143, 134],\n        [137, 146, 140],\n        ...,\n        [120, 133, 137],\n        [119, 136, 140],\n        [126, 143, 144]],\n\n       [[134, 140, 135],\n        [137, 143, 137],\n        [140, 146, 140],\n        ...,\n        [123, 134, 138],\n        [121, 132, 138],\n        [126, 136, 139]],\n\n       [[134, 140, 135],\n        [137, 142, 137],\n        [139, 142, 137],\n        ...,\n        [119, 130, 137],\n        [121, 130, 137],\n        [128, 136, 141]],\n\n       ...,\n\n       [[ 60,  68,  62],\n        [ 64,  71,  63],\n        [ 83,  92,  77],\n        ...,\n        [ 75,  84,  76],\n        [ 83,  90,  83],\n        [ 92,  98,  91]],\n\n       [[ 65,  70,  65],\n        [ 66,  73,  65],\n        [ 67,  73,  65],\n        ...,\n        [ 71,  82,  77],\n        [ 75,  84,  78],\n        [ 85,  90,  84]],\n\n       [[ 80,  83,  76],\n        [ 80,  81,  71],\n        [ 79,  80,  69],\n        ...,\n        [ 67,  76,  79],\n        [ 71,  76,  80],\n        [ 87,  87,  89]]], dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x0000020100A2BC70>, 1",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [2], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mregister_face\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mMayank Goel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mknown_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn [1], line 20\u001B[0m, in \u001B[0;36mregister_face\u001B[1;34m(name, known_path)\u001B[0m\n\u001B[0;32m     18\u001B[0m rgb_small_frame \u001B[38;5;241m=\u001B[39m small_frame[:, :, ::\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m     19\u001B[0m face_locations \u001B[38;5;241m=\u001B[39m face_recognition\u001B[38;5;241m.\u001B[39mface_locations(rgb_small_frame)\n\u001B[1;32m---> 20\u001B[0m face_encodings \u001B[38;5;241m=\u001B[39m \u001B[43mface_recognition\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mface_encodings\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrgb_small_frame\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mface_locations\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28mdir\u001B[39m \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(known_path, name)\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39misdir(\u001B[38;5;28mdir\u001B[39m):\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\face_recognition\\api.py:214\u001B[0m, in \u001B[0;36mface_encodings\u001B[1;34m(face_image, known_face_locations, num_jitters, model)\u001B[0m\n\u001B[0;32m    204\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    205\u001B[0m \u001B[38;5;124;03mGiven an image, return the 128-dimension face encoding for each face in the image.\u001B[39;00m\n\u001B[0;32m    206\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    211\u001B[0m \u001B[38;5;124;03m:return: A list of 128-dimensional face encodings (one for each face in the image)\u001B[39;00m\n\u001B[0;32m    212\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    213\u001B[0m raw_landmarks \u001B[38;5;241m=\u001B[39m _raw_face_landmarks(face_image, known_face_locations, model)\n\u001B[1;32m--> 214\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m [np\u001B[38;5;241m.\u001B[39marray(face_encoder\u001B[38;5;241m.\u001B[39mcompute_face_descriptor(face_image, raw_landmark_set, num_jitters)) \u001B[38;5;28;01mfor\u001B[39;00m raw_landmark_set \u001B[38;5;129;01min\u001B[39;00m raw_landmarks]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\face_recognition\\api.py:214\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    204\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    205\u001B[0m \u001B[38;5;124;03mGiven an image, return the 128-dimension face encoding for each face in the image.\u001B[39;00m\n\u001B[0;32m    206\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    211\u001B[0m \u001B[38;5;124;03m:return: A list of 128-dimensional face encodings (one for each face in the image)\u001B[39;00m\n\u001B[0;32m    212\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    213\u001B[0m raw_landmarks \u001B[38;5;241m=\u001B[39m _raw_face_landmarks(face_image, known_face_locations, model)\n\u001B[1;32m--> 214\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m [np\u001B[38;5;241m.\u001B[39marray(\u001B[43mface_encoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_face_descriptor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mface_image\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mraw_landmark_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_jitters\u001B[49m\u001B[43m)\u001B[49m) \u001B[38;5;28;01mfor\u001B[39;00m raw_landmark_set \u001B[38;5;129;01min\u001B[39;00m raw_landmarks]\n",
      "\u001B[1;31mTypeError\u001B[0m: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: List[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: List[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: List[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n\nInvoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000002010F6CF430>, array([[[137, 142, 133],\n        [133, 143, 134],\n        [137, 146, 140],\n        ...,\n        [120, 133, 137],\n        [119, 136, 140],\n        [126, 143, 144]],\n\n       [[134, 140, 135],\n        [137, 143, 137],\n        [140, 146, 140],\n        ...,\n        [123, 134, 138],\n        [121, 132, 138],\n        [126, 136, 139]],\n\n       [[134, 140, 135],\n        [137, 142, 137],\n        [139, 142, 137],\n        ...,\n        [119, 130, 137],\n        [121, 130, 137],\n        [128, 136, 141]],\n\n       ...,\n\n       [[ 60,  68,  62],\n        [ 64,  71,  63],\n        [ 83,  92,  77],\n        ...,\n        [ 75,  84,  76],\n        [ 83,  90,  83],\n        [ 92,  98,  91]],\n\n       [[ 65,  70,  65],\n        [ 66,  73,  65],\n        [ 67,  73,  65],\n        ...,\n        [ 71,  82,  77],\n        [ 75,  84,  78],\n        [ 85,  90,  84]],\n\n       [[ 80,  83,  76],\n        [ 80,  81,  71],\n        [ 79,  80,  69],\n        ...,\n        [ 67,  76,  79],\n        [ 71,  76,  80],\n        [ 87,  87,  89]]], dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x0000020100A2BC70>, 1"
     ]
    }
   ],
   "source": [
    "register_face(\"Mayank Goel\", known_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "'C:\\\\Users\\\\goelm\\\\PycharmProjects\\\\pythonProject'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# reset directory\n",
    "os.chdir(\"C:\\\\Users\\\\Mayank\\\\Desktop\\\\Face Recognition\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: List[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: List[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: List[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n\nInvoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001AE7EE6F8F0>, array([[[ 95, 102, 113],\n        [100, 104, 118],\n        [105, 108, 118],\n        ...,\n        [104, 117, 131],\n        [105, 119, 135],\n        [107, 117, 136]],\n\n       [[ 90,  97, 110],\n        [ 96, 101, 115],\n        [108, 112, 123],\n        ...,\n        [106, 116, 135],\n        [105, 116, 135],\n        [104, 117, 135]],\n\n       [[ 97, 102, 115],\n        [ 99, 106, 117],\n        [103, 110, 117],\n        ...,\n        [103, 114, 132],\n        [106, 116, 135],\n        [108, 118, 138]],\n\n       ...,\n\n       [[ 70,  74,  77],\n        [ 75,  76,  79],\n        [ 76,  78,  79],\n        ...,\n        [ 67,  71,  74],\n        [ 67,  71,  74],\n        [ 69,  73,  78]],\n\n       [[ 67,  70,  73],\n        [ 71,  75,  76],\n        [ 72,  76,  77],\n        ...,\n        [ 67,  72,  77],\n        [ 69,  72,  76],\n        [ 67,  73,  77]],\n\n       [[ 71,  76,  77],\n        [ 71,  74,  77],\n        [ 70,  74,  75],\n        ...,\n        [ 64,  70,  78],\n        [ 67,  70,  77],\n        [ 67,  73,  77]]], dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x000001AE7EE03EB0>, 1",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [10], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mrecognize_face\u001B[49m\u001B[43m(\u001B[49m\u001B[43mknown_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43munknown_path\u001B[49m\u001B[43m)\u001B[49m)\n",
      "Cell \u001B[1;32mIn [8], line 47\u001B[0m, in \u001B[0;36mrecognize_face\u001B[1;34m(known_path, unknown_path)\u001B[0m\n\u001B[0;32m     45\u001B[0m rgb_small_frame \u001B[38;5;241m=\u001B[39m small_frame[:, :, ::\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m     46\u001B[0m face_locations \u001B[38;5;241m=\u001B[39m face_recognition\u001B[38;5;241m.\u001B[39mface_locations(rgb_small_frame)\n\u001B[1;32m---> 47\u001B[0m face_encodings \u001B[38;5;241m=\u001B[39m \u001B[43mface_recognition\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mface_encodings\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrgb_small_frame\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mface_locations\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     48\u001B[0m face_names \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m face_encodings:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\face_recognition\\api.py:214\u001B[0m, in \u001B[0;36mface_encodings\u001B[1;34m(face_image, known_face_locations, num_jitters, model)\u001B[0m\n\u001B[0;32m    204\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    205\u001B[0m \u001B[38;5;124;03mGiven an image, return the 128-dimension face encoding for each face in the image.\u001B[39;00m\n\u001B[0;32m    206\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    211\u001B[0m \u001B[38;5;124;03m:return: A list of 128-dimensional face encodings (one for each face in the image)\u001B[39;00m\n\u001B[0;32m    212\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    213\u001B[0m raw_landmarks \u001B[38;5;241m=\u001B[39m _raw_face_landmarks(face_image, known_face_locations, model)\n\u001B[1;32m--> 214\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m [np\u001B[38;5;241m.\u001B[39marray(face_encoder\u001B[38;5;241m.\u001B[39mcompute_face_descriptor(face_image, raw_landmark_set, num_jitters)) \u001B[38;5;28;01mfor\u001B[39;00m raw_landmark_set \u001B[38;5;129;01min\u001B[39;00m raw_landmarks]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\face_recognition\\api.py:214\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    204\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    205\u001B[0m \u001B[38;5;124;03mGiven an image, return the 128-dimension face encoding for each face in the image.\u001B[39;00m\n\u001B[0;32m    206\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    211\u001B[0m \u001B[38;5;124;03m:return: A list of 128-dimensional face encodings (one for each face in the image)\u001B[39;00m\n\u001B[0;32m    212\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    213\u001B[0m raw_landmarks \u001B[38;5;241m=\u001B[39m _raw_face_landmarks(face_image, known_face_locations, model)\n\u001B[1;32m--> 214\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m [np\u001B[38;5;241m.\u001B[39marray(\u001B[43mface_encoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_face_descriptor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mface_image\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mraw_landmark_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_jitters\u001B[49m\u001B[43m)\u001B[49m) \u001B[38;5;28;01mfor\u001B[39;00m raw_landmark_set \u001B[38;5;129;01min\u001B[39;00m raw_landmarks]\n",
      "\u001B[1;31mTypeError\u001B[0m: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: List[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: List[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: List[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n\nInvoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001AE7EE6F8F0>, array([[[ 95, 102, 113],\n        [100, 104, 118],\n        [105, 108, 118],\n        ...,\n        [104, 117, 131],\n        [105, 119, 135],\n        [107, 117, 136]],\n\n       [[ 90,  97, 110],\n        [ 96, 101, 115],\n        [108, 112, 123],\n        ...,\n        [106, 116, 135],\n        [105, 116, 135],\n        [104, 117, 135]],\n\n       [[ 97, 102, 115],\n        [ 99, 106, 117],\n        [103, 110, 117],\n        ...,\n        [103, 114, 132],\n        [106, 116, 135],\n        [108, 118, 138]],\n\n       ...,\n\n       [[ 70,  74,  77],\n        [ 75,  76,  79],\n        [ 76,  78,  79],\n        ...,\n        [ 67,  71,  74],\n        [ 67,  71,  74],\n        [ 69,  73,  78]],\n\n       [[ 67,  70,  73],\n        [ 71,  75,  76],\n        [ 72,  76,  77],\n        ...,\n        [ 67,  72,  77],\n        [ 69,  72,  76],\n        [ 67,  73,  77]],\n\n       [[ 71,  76,  77],\n        [ 71,  74,  77],\n        [ 70,  74,  75],\n        ...,\n        [ 64,  70,  78],\n        [ 67,  70,  77],\n        [ 67,  73,  77]]], dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x000001AE7EE03EB0>, 1"
     ]
    }
   ],
   "source": [
    "print(recognize_face(known_path, unknown_path))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
